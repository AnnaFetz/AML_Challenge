{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnnaFetz/AML_Challenge/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21lvDhBg-0em"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIUSXffrEc_Q"
      },
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import pickle\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import tensorflow\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D, Reshape, Activation, LeakyReLU, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras import backend as K\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae3ZstLv3jSV",
        "outputId": "bf12f7e7-d4d4-4101-be76-28f83a40f038"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "import sys \n",
        "from google.colab import drive \n",
        "import glob\n",
        "\n",
        "path = \"/content/drive\" \n",
        "drive.mount(path, force_remount=True)  \n",
        "data_path = \"drive/MyDrive/challenge_AML/dataset\" \n",
        "\n",
        "myfiles = glob.glob(os.path.join(data_path, '*')) \n",
        "print(myfiles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Mounted at /content/drive\n",
            "Mounted at /content/drive\n",
            "['drive/MyDrive/challenge_AML/dataset/validation', 'drive/MyDrive/challenge_AML/dataset/training', 'drive/MyDrive/challenge_AML/dataset/test']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP7echf-lnQc"
      },
      "source": [
        "class Dataset(object):\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        assert os.path.exists(self.data_path), 'Insert a valid path!'\n",
        "\n",
        "        # get class list\n",
        "        self.data_classes = os.listdir(self.data_path)\n",
        "\n",
        "        # init mapping dict\n",
        "        self.data_mapping = {}\n",
        "\n",
        "        # populate mapping dict\n",
        "        for c, c_name in enumerate(self.data_classes):\n",
        "            temp_path = os.path.join(self.data_path, c_name)\n",
        "            temp_images = os.listdir(temp_path)\n",
        "\n",
        "            for i in temp_images:\n",
        "                img_tmp = os.path.join(temp_path, i)\n",
        "\n",
        "                if img_tmp.endswith('.jpg'):\n",
        "                    if c_name == 'distractor':\n",
        "                        self.data_mapping[img_tmp] = -1\n",
        "                    else:\n",
        "                        self.data_mapping[img_tmp] = int(c_name)\n",
        "\n",
        "        print('Loaded {:d} from {:s} images'.format(len(self.data_mapping.keys()),\n",
        "                                                    self.data_path))\n",
        "\n",
        "    def get_data_paths(self):\n",
        "        # returns a list of imgpaths and related classes\n",
        "        images = []\n",
        "        classes = []\n",
        "        for img_path in self.data_mapping.keys():\n",
        "            if img_path.endswith('.jpg'):\n",
        "                images.append(img_path)\n",
        "                classes.append(self.data_mapping[img_path])\n",
        "        return images, np.array(classes)\n",
        "\n",
        "\n",
        "    def num_classes(self):\n",
        "        # returns number of classes of the dataset\n",
        "        return len(self.data_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMU-qrb1lrcY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64643288-3fc1-4f4a-83fb-755d7512e383"
      },
      "source": [
        "validation_path = os.path.join(data_path, 'validation')\n",
        "test_path= os.path.join(data_path, \"test\")\n",
        "gallery_path = os.path.join(validation_path, 'gallery')\n",
        "query_path = os.path.join(validation_path, 'query')\n",
        "training_path = os.path.join(data_path, \"training\") \n",
        "\n",
        "training_dataset = Dataset(data_path = training_path)\n",
        "gallery_dataset = Dataset(data_path=gallery_path)\n",
        "query_dataset = Dataset(data_path=query_path)\n",
        "test_dataset = Dataset(data_path = test_path)\n",
        "\n",
        "# get training data and classes\n",
        "training_paths, training_classes = training_dataset.get_data_paths()\n",
        "test_paths, test_classes = test_dataset.get_data_paths()\n",
        "# we get validation gallery and query data\n",
        "gallery_paths, gallery_classes = gallery_dataset.get_data_paths()\n",
        "query_paths, query_classes = query_dataset.get_data_paths()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 39218 from drive/MyDrive/challenge_AML/dataset/training images\n",
            "Loaded 534 from drive/MyDrive/challenge_AML/dataset/validation/gallery images\n",
            "Loaded 70 from drive/MyDrive/challenge_AML/dataset/validation/query images\n",
            "Loaded 59 from drive/MyDrive/challenge_AML/dataset/test images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4tqYc_USVBm",
        "outputId": "e1a1570a-c653-4366-a6ba-63fdd83ac83f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['4', 'distractor', '6', '8', '5', '9', '7', '3', '31', '2', '19', '16', '37', '35', '14', '18', '15', '13', '12', '1', '11', '10']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh3pSUM6D0ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1c8e28-0d64-492e-d301-ac675aec02ad"
      },
      "source": [
        "datagen = ImageDataGenerator(featurewise_center=False, samplewise_center=True, \n",
        "                             featurewise_std_normalization=True, samplewise_std_normalization=True, \n",
        "                             rotation_range=20, width_shift_range=0.3, height_shift_range=0.3, brightness_range=None, \n",
        "                             shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0, fill_mode=\"nearest\", cval=0.0,\n",
        "                             horizontal_flip=True, vertical_flip=True, rescale=None, preprocessing_function=None, data_format=None,\n",
        "                             validation_split=0.4, dtype=None, \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:349: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gorKxm02yDw2",
        "outputId": "3e18467d-20c1-4761-f3a4-8b28a6e41b86"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "\n",
        "training_set = datagen.flow_from_directory(\n",
        "    training_path,\n",
        "     batch_size = batch_size,\n",
        "     class_mode = 'input',\n",
        "     subset = 'training',\n",
        "     shuffle=True)\n",
        "\n",
        "\n",
        "validation_set = datagen.flow_from_directory(\n",
        "    training_path,\n",
        "    target_size = (256, 256),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'input',\n",
        "    subset = 'validation',\n",
        "    shuffle=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 23537 images belonging to 22 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([[[[ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         [ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         [ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         ...,\n",
            "         [ 0.69863737,  0.34014103,  0.10967909],\n",
            "         [ 0.69863737,  0.34014103,  0.10967909],\n",
            "         [ 0.69863737,  0.34014103,  0.10967909]],\n",
            "\n",
            "        [[ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         [ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         [ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         ...,\n",
            "         [ 0.69863737,  0.34014103,  0.10967909],\n",
            "         [ 0.69863737,  0.34014103,  0.10967909],\n",
            "         [ 0.69863737,  0.34014103,  0.10967909]],\n",
            "\n",
            "        [[ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         [ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         [ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         ...,\n",
            "         [ 0.69863737,  0.34014103,  0.10967909],\n",
            "         [ 0.69863737,  0.34014103,  0.10967909],\n",
            "         [ 0.69863737,  0.34014103,  0.10967909]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         [ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         [ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         ...,\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909],\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909],\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909]],\n",
            "\n",
            "        [[ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         [ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         [ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         ...,\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909],\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909],\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909]],\n",
            "\n",
            "        [[ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         [ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         [ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         ...,\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909],\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909],\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909]]],\n",
            "\n",
            "\n",
            "       [[[ 0.63911784,  0.30867526,  0.04904179],\n",
            "         [ 0.63911784,  0.30867526,  0.04904179],\n",
            "         [ 0.63911784,  0.30867526,  0.04904179],\n",
            "         ...,\n",
            "         [ 0.6404065 ,  0.30996388,  0.0975365 ],\n",
            "         [ 0.66272086,  0.33227828,  0.11985091],\n",
            "         [ 0.66295713,  0.33251455,  0.12008718]],\n",
            "\n",
            "        [[ 0.63911784,  0.30867526,  0.04904179],\n",
            "         [ 0.63911784,  0.30867526,  0.04904179],\n",
            "         [ 0.63911784,  0.30867526,  0.04904179],\n",
            "         ...,\n",
            "         [ 0.6453629 ,  0.3149203 ,  0.10249294],\n",
            "         [ 0.66272086,  0.33227828,  0.11985091],\n",
            "         [ 0.6679132 ,  0.33747062,  0.12504326]],\n",
            "\n",
            "        [[ 0.63911784,  0.30867526,  0.04904179],\n",
            "         [ 0.63911784,  0.30867526,  0.04904179],\n",
            "         [ 0.63911784,  0.30867526,  0.04904179],\n",
            "         ...,\n",
            "         [ 0.650319  ,  0.3198764 ,  0.10744902],\n",
            "         [ 0.66272086,  0.33227828,  0.11985091],\n",
            "         [ 0.6728697 ,  0.34242707,  0.12999968]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         [ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         [ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         ...,\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ],\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ],\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ]],\n",
            "\n",
            "        [[ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         [ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         [ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         ...,\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ],\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ],\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ]],\n",
            "\n",
            "        [[ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         [ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         [ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         ...,\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ],\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ],\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ]]],\n",
            "\n",
            "\n",
            "       [[[ 0.41133055,  0.77554256,  0.9436405 ],\n",
            "         [ 0.58585835,  0.9500704 ,  1.1181682 ],\n",
            "         [ 0.5978487 ,  0.9620608 ,  1.1541389 ],\n",
            "         ...,\n",
            "         [-0.6591725 , -0.7924477 , -1.0977464 ],\n",
            "         [-0.59995097, -0.72265077, -1.0321796 ],\n",
            "         [-0.5407292 , -0.65285385, -0.96661276]],\n",
            "\n",
            "        [[ 0.30014935,  0.6643614 ,  0.8324593 ],\n",
            "         [ 0.45602342,  0.8202355 ,  0.98833334],\n",
            "         [ 0.44753852,  0.81175053,  0.9897873 ],\n",
            "         ...,\n",
            "         [-0.17666316, -0.20772003, -0.51894003],\n",
            "         [-0.16820303, -0.19502984, -0.5020195 ],\n",
            "         [-0.1597427 , -0.18233943, -0.48509908]],\n",
            "\n",
            "        [[-0.46436748, -0.11937199,  0.02950955],\n",
            "         [-0.23814356,  0.10262188,  0.24727336],\n",
            "         [-0.23135942,  0.10517617,  0.2532634 ],\n",
            "         ...,\n",
            "         [-0.13936508, -0.10214137, -0.39471254],\n",
            "         [-0.14359535, -0.10002656, -0.39471254],\n",
            "         [-0.14782542, -0.09791131, -0.39471254]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.6742523 , -1.2820239 , -1.1979749 ],\n",
            "         [-1.3882421 , -0.9960137 , -0.9119648 ],\n",
            "         [-0.3211883 ,  0.07103983,  0.15508877],\n",
            "         ...,\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ],\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ],\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ]],\n",
            "\n",
            "        [[-1.6509867 , -1.2587583 , -1.1747094 ],\n",
            "         [-1.50034   , -1.1081116 , -1.0240628 ],\n",
            "         [-0.33810878,  0.05411958,  0.13816851],\n",
            "         ...,\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ],\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ],\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ]],\n",
            "\n",
            "        [[-1.627721  , -1.2354926 , -1.1514436 ],\n",
            "         [-1.6124382 , -1.2202098 , -1.1361609 ],\n",
            "         [-0.35502923,  0.0371989 ,  0.12124784],\n",
            "         ...,\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ],\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ],\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[-0.1466083 , -0.34744847, -0.41428995],\n",
            "         [-0.03691989, -0.35915396, -0.54101217],\n",
            "         [ 0.1793497 , -0.23811197, -0.5360723 ],\n",
            "         ...,\n",
            "         [ 3.375133  ,  2.5343332 ,  2.0844464 ],\n",
            "         [ 3.375133  ,  2.5343332 ,  2.0874217 ],\n",
            "         [ 3.375133  ,  2.5343332 ,  2.090397  ]],\n",
            "\n",
            "        [[ 0.31230366,  0.11164369, -0.0110478 ],\n",
            "         [ 0.34464154,  0.04370262, -0.19304468],\n",
            "         [ 0.38821632, -0.00846203, -0.31282675],\n",
            "         ...,\n",
            "         [ 3.375133  ,  2.5495632 ,  2.1091442 ],\n",
            "         [ 3.375133  ,  2.551051  ,  2.110632  ],\n",
            "         [ 3.375133  ,  2.5525382 ,  2.1121192 ]],\n",
            "\n",
            "        [[ 0.33223823,  0.1385559 ,  0.02224742],\n",
            "         [ 0.35260397,  0.05688151, -0.17558163],\n",
            "         [ 0.4077509 ,  0.01757394, -0.2855787 ],\n",
            "         ...,\n",
            "         [ 3.3599586 ,  2.539178  ,  2.1291077 ],\n",
            "         [ 3.3584712 ,  2.5376904 ,  2.1305952 ],\n",
            "         [ 3.3569834 ,  2.5362027 ,  2.132083  ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.8875832 , -0.8178516 , -1.0767589 ],\n",
            "         [-0.82315177, -0.74307555, -1.0625994 ],\n",
            "         [-0.70875216, -0.62867594, -0.96899974],\n",
            "         ...,\n",
            "         [-0.2883522 , -0.56861883, -0.62867594],\n",
            "         [-0.2883522 , -0.56861883, -0.62867594],\n",
            "         [-0.2883522 , -0.56861883, -0.62867594]],\n",
            "\n",
            "        [[-0.88163275, -0.8133888 , -1.0663456 ],\n",
            "         [-0.8395155 , -0.75943935, -1.0759879 ],\n",
            "         [-0.70875216, -0.62867594, -0.96899974],\n",
            "         ...,\n",
            "         [-0.2883522 , -0.56861883, -0.62867594],\n",
            "         [-0.2883522 , -0.56861883, -0.62867594],\n",
            "         [-0.2883522 , -0.56861883, -0.62867594]],\n",
            "\n",
            "        [[-0.8756823 , -0.808926  , -1.0559323 ],\n",
            "         [-0.8558792 , -0.775803  , -1.0893764 ],\n",
            "         [-0.70875216, -0.62867594, -0.96899974],\n",
            "         ...,\n",
            "         [-0.2883522 , -0.56861883, -0.62867594],\n",
            "         [-0.2883522 , -0.56861883, -0.62867594],\n",
            "         [-0.2883522 , -0.56861883, -0.62867594]]],\n",
            "\n",
            "\n",
            "       [[[ 0.7421956 ,  0.4015919 ,  0.26134333],\n",
            "         [ 0.7421956 ,  0.4015919 ,  0.26134333],\n",
            "         [ 0.73627657,  0.39567292,  0.25542432],\n",
            "         ...,\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985],\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985],\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985]],\n",
            "\n",
            "        [[ 0.7421956 ,  0.4015919 ,  0.26134333],\n",
            "         [ 0.7421956 ,  0.4015919 ,  0.26134333],\n",
            "         [ 0.7375184 ,  0.39691472,  0.25666615],\n",
            "         ...,\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985],\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985],\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985]],\n",
            "\n",
            "        [[ 0.7421956 ,  0.4015919 ,  0.26134333],\n",
            "         [ 0.7421956 ,  0.4015919 ,  0.26134333],\n",
            "         [ 0.73876053,  0.39815685,  0.25790828],\n",
            "         ...,\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985],\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985],\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.78994286,  0.5094457 ,  0.32912612],\n",
            "         [ 0.7822666 ,  0.5017695 ,  0.32144985],\n",
            "         [ 0.7699844 ,  0.48948726,  0.30916765],\n",
            "         ...,\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ],\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ],\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ]],\n",
            "\n",
            "        [[ 0.79118466,  0.51068753,  0.33036795],\n",
            "         [ 0.7822666 ,  0.5017695 ,  0.32144985],\n",
            "         [ 0.7712262 ,  0.49072906,  0.3104095 ],\n",
            "         ...,\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ],\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ],\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ]],\n",
            "\n",
            "        [[ 0.7924268 ,  0.5119297 ,  0.33161008],\n",
            "         [ 0.7822666 ,  0.5017695 ,  0.32144985],\n",
            "         [ 0.7724683 ,  0.4919712 ,  0.31165162],\n",
            "         ...,\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ],\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ],\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ]]],\n",
            "\n",
            "\n",
            "       [[[ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         [ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         [ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         ...,\n",
            "         [ 0.83069247,  0.55737764,  0.42875892],\n",
            "         [ 0.83456045,  0.5612456 ,  0.43262687],\n",
            "         [ 0.8384282 ,  0.56511337,  0.43649462]],\n",
            "\n",
            "        [[ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         [ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         [ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         ...,\n",
            "         [ 0.8437423 ,  0.5704275 ,  0.44180873],\n",
            "         [ 0.8437423 ,  0.5704275 ,  0.44180873],\n",
            "         [ 0.8437423 ,  0.5704275 ,  0.44180873]],\n",
            "\n",
            "        [[ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         [ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         [ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         ...,\n",
            "         [ 0.8437423 ,  0.5704275 ,  0.44180873],\n",
            "         [ 0.8437423 ,  0.5704275 ,  0.44180873],\n",
            "         [ 0.8437423 ,  0.5704275 ,  0.44180873]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         [ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         [ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         ...,\n",
            "         [ 0.85981965,  0.6668915 ,  0.47396344],\n",
            "         [ 0.884955  ,  0.69202685,  0.49909875],\n",
            "         [ 0.9040699 ,  0.71114177,  0.5182136 ]],\n",
            "\n",
            "        [[ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         [ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         [ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         ...,\n",
            "         [ 0.85981965,  0.6668915 ,  0.47396344],\n",
            "         [ 0.87721926,  0.6842912 ,  0.49136305],\n",
            "         [ 0.9002019 ,  0.7072738 ,  0.5143457 ]],\n",
            "\n",
            "        [[ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         [ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         [ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         ...,\n",
            "         [ 0.85981965,  0.6668915 ,  0.47396344],\n",
            "         [ 0.86948335,  0.6765552 ,  0.4836271 ],\n",
            "         [ 0.89633393,  0.7034058 ,  0.5104777 ]]]], dtype=float32), array([[[[ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         [ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         [ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         ...,\n",
            "         [ 0.69863737,  0.34014103,  0.10967909],\n",
            "         [ 0.69863737,  0.34014103,  0.10967909],\n",
            "         [ 0.69863737,  0.34014103,  0.10967909]],\n",
            "\n",
            "        [[ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         [ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         [ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         ...,\n",
            "         [ 0.69863737,  0.34014103,  0.10967909],\n",
            "         [ 0.69863737,  0.34014103,  0.10967909],\n",
            "         [ 0.69863737,  0.34014103,  0.10967909]],\n",
            "\n",
            "        [[ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         [ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         [ 0.6730305 ,  0.28892726,  0.10967909],\n",
            "         ...,\n",
            "         [ 0.69863737,  0.34014103,  0.10967909],\n",
            "         [ 0.69863737,  0.34014103,  0.10967909],\n",
            "         [ 0.69863737,  0.34014103,  0.10967909]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         [ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         [ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         ...,\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909],\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909],\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909]],\n",
            "\n",
            "        [[ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         [ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         [ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         ...,\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909],\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909],\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909]],\n",
            "\n",
            "        [[ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         [ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         [ 0.6730305 ,  0.2377135 ,  0.05846532],\n",
            "         ...,\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909],\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909],\n",
            "         [ 0.7498511 ,  0.31453413,  0.10967909]]],\n",
            "\n",
            "\n",
            "       [[[ 0.63911784,  0.30867526,  0.04904179],\n",
            "         [ 0.63911784,  0.30867526,  0.04904179],\n",
            "         [ 0.63911784,  0.30867526,  0.04904179],\n",
            "         ...,\n",
            "         [ 0.6404065 ,  0.30996388,  0.0975365 ],\n",
            "         [ 0.66272086,  0.33227828,  0.11985091],\n",
            "         [ 0.66295713,  0.33251455,  0.12008718]],\n",
            "\n",
            "        [[ 0.63911784,  0.30867526,  0.04904179],\n",
            "         [ 0.63911784,  0.30867526,  0.04904179],\n",
            "         [ 0.63911784,  0.30867526,  0.04904179],\n",
            "         ...,\n",
            "         [ 0.6453629 ,  0.3149203 ,  0.10249294],\n",
            "         [ 0.66272086,  0.33227828,  0.11985091],\n",
            "         [ 0.6679132 ,  0.33747062,  0.12504326]],\n",
            "\n",
            "        [[ 0.63911784,  0.30867526,  0.04904179],\n",
            "         [ 0.63911784,  0.30867526,  0.04904179],\n",
            "         [ 0.63911784,  0.30867526,  0.04904179],\n",
            "         ...,\n",
            "         [ 0.650319  ,  0.3198764 ,  0.10744902],\n",
            "         [ 0.66272086,  0.33227828,  0.11985091],\n",
            "         [ 0.6728697 ,  0.34242707,  0.12999968]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         [ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         [ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         ...,\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ],\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ],\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ]],\n",
            "\n",
            "        [[ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         [ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         [ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         ...,\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ],\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ],\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ]],\n",
            "\n",
            "        [[ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         [ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         [ 0.70992696,  0.2850722 ,  0.23786612],\n",
            "         ...,\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ],\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ],\n",
            "         [ 0.75713307,  0.35588133,  0.167057  ]]],\n",
            "\n",
            "\n",
            "       [[[ 0.41133055,  0.77554256,  0.9436405 ],\n",
            "         [ 0.58585835,  0.9500704 ,  1.1181682 ],\n",
            "         [ 0.5978487 ,  0.9620608 ,  1.1541389 ],\n",
            "         ...,\n",
            "         [-0.6591725 , -0.7924477 , -1.0977464 ],\n",
            "         [-0.59995097, -0.72265077, -1.0321796 ],\n",
            "         [-0.5407292 , -0.65285385, -0.96661276]],\n",
            "\n",
            "        [[ 0.30014935,  0.6643614 ,  0.8324593 ],\n",
            "         [ 0.45602342,  0.8202355 ,  0.98833334],\n",
            "         [ 0.44753852,  0.81175053,  0.9897873 ],\n",
            "         ...,\n",
            "         [-0.17666316, -0.20772003, -0.51894003],\n",
            "         [-0.16820303, -0.19502984, -0.5020195 ],\n",
            "         [-0.1597427 , -0.18233943, -0.48509908]],\n",
            "\n",
            "        [[-0.46436748, -0.11937199,  0.02950955],\n",
            "         [-0.23814356,  0.10262188,  0.24727336],\n",
            "         [-0.23135942,  0.10517617,  0.2532634 ],\n",
            "         ...,\n",
            "         [-0.13936508, -0.10214137, -0.39471254],\n",
            "         [-0.14359535, -0.10002656, -0.39471254],\n",
            "         [-0.14782542, -0.09791131, -0.39471254]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.6742523 , -1.2820239 , -1.1979749 ],\n",
            "         [-1.3882421 , -0.9960137 , -0.9119648 ],\n",
            "         [-0.3211883 ,  0.07103983,  0.15508877],\n",
            "         ...,\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ],\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ],\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ]],\n",
            "\n",
            "        [[-1.6509867 , -1.2587583 , -1.1747094 ],\n",
            "         [-1.50034   , -1.1081116 , -1.0240628 ],\n",
            "         [-0.33810878,  0.05411958,  0.13816851],\n",
            "         ...,\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ],\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ],\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ]],\n",
            "\n",
            "        [[-1.627721  , -1.2354926 , -1.1514436 ],\n",
            "         [-1.6124382 , -1.2202098 , -1.1361609 ],\n",
            "         [-0.35502923,  0.0371989 ,  0.12124784],\n",
            "         ...,\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ],\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ],\n",
            "         [ 0.9780867 ,  0.9780867 ,  0.641891  ]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[-0.1466083 , -0.34744847, -0.41428995],\n",
            "         [-0.03691989, -0.35915396, -0.54101217],\n",
            "         [ 0.1793497 , -0.23811197, -0.5360723 ],\n",
            "         ...,\n",
            "         [ 3.375133  ,  2.5343332 ,  2.0844464 ],\n",
            "         [ 3.375133  ,  2.5343332 ,  2.0874217 ],\n",
            "         [ 3.375133  ,  2.5343332 ,  2.090397  ]],\n",
            "\n",
            "        [[ 0.31230366,  0.11164369, -0.0110478 ],\n",
            "         [ 0.34464154,  0.04370262, -0.19304468],\n",
            "         [ 0.38821632, -0.00846203, -0.31282675],\n",
            "         ...,\n",
            "         [ 3.375133  ,  2.5495632 ,  2.1091442 ],\n",
            "         [ 3.375133  ,  2.551051  ,  2.110632  ],\n",
            "         [ 3.375133  ,  2.5525382 ,  2.1121192 ]],\n",
            "\n",
            "        [[ 0.33223823,  0.1385559 ,  0.02224742],\n",
            "         [ 0.35260397,  0.05688151, -0.17558163],\n",
            "         [ 0.4077509 ,  0.01757394, -0.2855787 ],\n",
            "         ...,\n",
            "         [ 3.3599586 ,  2.539178  ,  2.1291077 ],\n",
            "         [ 3.3584712 ,  2.5376904 ,  2.1305952 ],\n",
            "         [ 3.3569834 ,  2.5362027 ,  2.132083  ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.8875832 , -0.8178516 , -1.0767589 ],\n",
            "         [-0.82315177, -0.74307555, -1.0625994 ],\n",
            "         [-0.70875216, -0.62867594, -0.96899974],\n",
            "         ...,\n",
            "         [-0.2883522 , -0.56861883, -0.62867594],\n",
            "         [-0.2883522 , -0.56861883, -0.62867594],\n",
            "         [-0.2883522 , -0.56861883, -0.62867594]],\n",
            "\n",
            "        [[-0.88163275, -0.8133888 , -1.0663456 ],\n",
            "         [-0.8395155 , -0.75943935, -1.0759879 ],\n",
            "         [-0.70875216, -0.62867594, -0.96899974],\n",
            "         ...,\n",
            "         [-0.2883522 , -0.56861883, -0.62867594],\n",
            "         [-0.2883522 , -0.56861883, -0.62867594],\n",
            "         [-0.2883522 , -0.56861883, -0.62867594]],\n",
            "\n",
            "        [[-0.8756823 , -0.808926  , -1.0559323 ],\n",
            "         [-0.8558792 , -0.775803  , -1.0893764 ],\n",
            "         [-0.70875216, -0.62867594, -0.96899974],\n",
            "         ...,\n",
            "         [-0.2883522 , -0.56861883, -0.62867594],\n",
            "         [-0.2883522 , -0.56861883, -0.62867594],\n",
            "         [-0.2883522 , -0.56861883, -0.62867594]]],\n",
            "\n",
            "\n",
            "       [[[ 0.7421956 ,  0.4015919 ,  0.26134333],\n",
            "         [ 0.7421956 ,  0.4015919 ,  0.26134333],\n",
            "         [ 0.73627657,  0.39567292,  0.25542432],\n",
            "         ...,\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985],\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985],\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985]],\n",
            "\n",
            "        [[ 0.7421956 ,  0.4015919 ,  0.26134333],\n",
            "         [ 0.7421956 ,  0.4015919 ,  0.26134333],\n",
            "         [ 0.7375184 ,  0.39691472,  0.25666615],\n",
            "         ...,\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985],\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985],\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985]],\n",
            "\n",
            "        [[ 0.7421956 ,  0.4015919 ,  0.26134333],\n",
            "         [ 0.7421956 ,  0.4015919 ,  0.26134333],\n",
            "         [ 0.73876053,  0.39815685,  0.25790828],\n",
            "         ...,\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985],\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985],\n",
            "         [ 0.8023021 ,  0.46169844,  0.32144985]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.78994286,  0.5094457 ,  0.32912612],\n",
            "         [ 0.7822666 ,  0.5017695 ,  0.32144985],\n",
            "         [ 0.7699844 ,  0.48948726,  0.30916765],\n",
            "         ...,\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ],\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ],\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ]],\n",
            "\n",
            "        [[ 0.79118466,  0.51068753,  0.33036795],\n",
            "         [ 0.7822666 ,  0.5017695 ,  0.32144985],\n",
            "         [ 0.7712262 ,  0.49072906,  0.3104095 ],\n",
            "         ...,\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ],\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ],\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ]],\n",
            "\n",
            "        [[ 0.7924268 ,  0.5119297 ,  0.33161008],\n",
            "         [ 0.7822666 ,  0.5017695 ,  0.32144985],\n",
            "         [ 0.7724683 ,  0.4919712 ,  0.31165162],\n",
            "         ...,\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ],\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ],\n",
            "         [ 0.70212454,  0.4216274 ,  0.2012368 ]]],\n",
            "\n",
            "\n",
            "       [[[ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         [ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         [ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         ...,\n",
            "         [ 0.83069247,  0.55737764,  0.42875892],\n",
            "         [ 0.83456045,  0.5612456 ,  0.43262687],\n",
            "         [ 0.8384282 ,  0.56511337,  0.43649462]],\n",
            "\n",
            "        [[ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         [ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         [ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         ...,\n",
            "         [ 0.8437423 ,  0.5704275 ,  0.44180873],\n",
            "         [ 0.8437423 ,  0.5704275 ,  0.44180873],\n",
            "         [ 0.8437423 ,  0.5704275 ,  0.44180873]],\n",
            "\n",
            "        [[ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         [ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         [ 0.924129  ,  0.6508142 ,  0.49004078],\n",
            "         ...,\n",
            "         [ 0.8437423 ,  0.5704275 ,  0.44180873],\n",
            "         [ 0.8437423 ,  0.5704275 ,  0.44180873],\n",
            "         [ 0.8437423 ,  0.5704275 ,  0.44180873]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         [ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         [ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         ...,\n",
            "         [ 0.85981965,  0.6668915 ,  0.47396344],\n",
            "         [ 0.884955  ,  0.69202685,  0.49909875],\n",
            "         [ 0.9040699 ,  0.71114177,  0.5182136 ]],\n",
            "\n",
            "        [[ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         [ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         [ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         ...,\n",
            "         [ 0.85981965,  0.6668915 ,  0.47396344],\n",
            "         [ 0.87721926,  0.6842912 ,  0.49136305],\n",
            "         [ 0.9002019 ,  0.7072738 ,  0.5143457 ]],\n",
            "\n",
            "        [[ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         [ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         [ 1.0045158 ,  0.73120093,  0.60258216],\n",
            "         ...,\n",
            "         [ 0.85981965,  0.6668915 ,  0.47396344],\n",
            "         [ 0.86948335,  0.6765552 ,  0.4836271 ],\n",
            "         [ 0.89633393,  0.7034058 ,  0.5104777 ]]]], dtype=float32))\n",
            "Found 15681 images belonging to 22 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA-k-P-D35kq"
      },
      "source": [
        "input_model = Input(shape=(256, 256, 3))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCy4-0pBEFPD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpyP7_jLkNdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8dcdbd-77ce-48b7-90ec-711f6b5e6156"
      },
      "source": [
        "def mymodel1(input_img, TRAINABLE=False):\n",
        "\n",
        " # base_model = VGG16(include_top = False, weights='imagenet', input_shape=(256,256,3))\n",
        "\n",
        "  #for layer in base_model.layers:\n",
        "  #  layer.trainable=TRAINABLE\n",
        "    \n",
        "  # Define the autoencoder\n",
        "  input_model = input_img\n",
        " \n",
        "  # Encoder layers\n",
        "  encoder = Conv2D(32, (3,3), padding='same', kernel_initializer='normal')(input_model)\n",
        "  encoder = LeakyReLU()(encoder)\n",
        "  encoder = BatchNormalization(axis=-1)(encoder)\n",
        "\n",
        "  encoder = Conv2D(64, (3,3), padding='same', kernel_initializer='normal')(encoder)\n",
        "  encoder = LeakyReLU()(encoder)\n",
        "  encoder = BatchNormalization(axis=-1)(encoder)\n",
        "\n",
        "  encoder = Conv2D(64, (3,3), padding='same', kernel_initializer='normal')(input_model)\n",
        "  encoder = LeakyReLU()(encoder)\n",
        "  encoder = BatchNormalization(axis=-1)(encoder)\n",
        "\n",
        "  encoder_dim = K.int_shape(encoder)\n",
        "  encoder = Flatten()(encoder)\n",
        "\n",
        "  # Latent Space\n",
        "  latent_space = Dense(16, name='latent_space')(encoder)\n",
        " \n",
        "\n",
        "  # Decoder Layers\n",
        "  decoder = Dense(np.prod(encoder_dim[1:]))(latent_space)\n",
        "  decoder = Reshape((encoder_dim[1], encoder_dim[2], encoder_dim[3]))(decoder)\n",
        "\n",
        "  decoder = Conv2DTranspose(64, (3,3), padding='same', kernel_initializer='normal')(decoder)\n",
        "  decoder = LeakyReLU()(decoder)\n",
        "  decoder = BatchNormalization(axis=-1)(decoder)\n",
        "\n",
        "  decoder = Conv2DTranspose(64, (3,3), padding='same', kernel_initializer='normal')(decoder)\n",
        "  decoder = LeakyReLU()(decoder)\n",
        "  decoder = BatchNormalization(axis=-1)(decoder)\n",
        "\n",
        "  decoder = Conv2DTranspose(32, (3,3), padding='same', kernel_initializer='normal')(decoder)\n",
        "  decoder = LeakyReLU()(decoder)\n",
        "  decoder = BatchNormalization(axis=-1)(decoder)\n",
        "\n",
        "  decoder = Conv2DTranspose(3, (3, 3), padding=\"same\")(decoder)\n",
        "  output = Activation('sigmoid', name='decoder')(decoder)\n",
        "\n",
        "  # Create model object\n",
        "  autoencoder = Model(input_model, output, name='autoencoder')\n",
        "\n",
        "  return autoencoder\n",
        "  # Compile the model\n",
        "  #autoencoder.compile(loss=\"mse\", optimizer= Adam(learning_rate=1e-3))\n",
        "  \n",
        "\n",
        "\n",
        "autoencoder=mymodel1(input_model)\n",
        "autoencoder.compile(loss='mean_squared_error', optimizer = Adam())\n",
        "autoencoder.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 256, 256, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256, 256, 64)      256       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4194304)           0         \n",
            "_________________________________________________________________\n",
            "latent_space (Dense)         (None, 16)                67108880  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4194304)           71303168  \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 256, 256, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 256, 256, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 256, 256, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 256, 256, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256, 256, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 256, 256, 32)      18464     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 256, 256, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 256, 256, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 256, 256, 3)       867       \n",
            "_________________________________________________________________\n",
            "decoder (Activation)         (None, 256, 256, 3)       0         \n",
            "=================================================================\n",
            "Total params: 138,507,923\n",
            "Trainable params: 138,507,475\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "catfuY6d0xWq",
        "outputId": "487f4fe9-0f64-4a09-bd56-fcb100f69cf3"
      },
      "source": [
        "# Fit the model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "history = autoencoder.fit_generator(\n",
        "          training_set,\n",
        "          steps_per_epoch=training_set.n // batch_size*2,\n",
        "          epochs=50,\n",
        "          validation_data=validation_set,\n",
        "          validation_steps=validation_set.n // batch_size,\n",
        "          callbacks = [ModelCheckpoint('drive/MyDrive/challenge_AML/checkpoints', \n",
        "                                       monitor='val_loss', \n",
        "                                       verbose=0, \n",
        "                                       save_best_only=True)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1260/1471 [========================>.....] - ETA: 9:45 - loss: 0.7217"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b1056cf6cfdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                                        \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                        save_best_only=True)])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fcd72859d10>\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2896, in open\n    \"cannot identify image file %r\" % (filename if filename else fp)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fcd72859d10>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_7]]\n  (1) Unknown:  UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fcd72859d10>\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2896, in open\n    \"cannot identify image file %r\" % (filename if filename else fp)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fcd72859d10>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1708]\n\nFunction call stack:\ntrain_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4n0dHz-4EX2"
      },
      "source": [
        "latent_space_model = Model(\n",
        "                      autoencoder.input, \n",
        "                      autoencoder.get_layer(latent_space).output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRg8jRhm4MG8"
      },
      "source": [
        "# Load all images and predict them with the latent space model\n",
        "def latent_space(path):\n",
        "\n",
        "  X = []\n",
        "  indices = []\n",
        "\n",
        "  for i in tqdm(range(len(path)))):\n",
        "    try:\n",
        "      img_name = training_paths[i]\n",
        "      img = load_img(os.path.join(path,img_name)), \n",
        "                    target_size = (256, 256))\n",
        "      img = img_to_array(img) / 255.0\n",
        "      img = np.expand_dims(img, axis=0)\n",
        "      pred = latent_space_model.predict(img)\n",
        "      pred = np.resize(pred, (16))\n",
        "      X.append(pred)\n",
        "      indices.append(img_name)\n",
        "\n",
        "    except Exception as e:\n",
        "      print(img_name)\n",
        "      print(e)\n",
        "          # Export the embeddings\n",
        "  embeddings = {'indices': indices, 'features': np.array(X)}\n",
        "  pickle.dump(embeddings, \n",
        "              open('drive/MyDrive/challenge_AML/pick.pickle', 'wb'))\n",
        "\n",
        "  return X, indices\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6TLh9H0iusA"
      },
      "source": [
        "query_array, query_img = latent_space(query_paths)\n",
        "gallery_array, gallery_img = latent_space(gallery_paths)\n",
        "\n",
        "def eucledian_distance(x,y):\n",
        "  eucl_dist = np.linalg.norm(x - y)\n",
        "  return eucl_dist\n",
        "\n",
        "def top_images() :\n",
        "  \n",
        "  distances = {}\n",
        "  for query_array, query_img in latent_space(query_paths):\n",
        "    distances[query_img] = []\n",
        "    for gallery_array, gallery_img in latent_space(gallery_paths):\n",
        "      distances = eucledian_distance(query_array,gallery_array)\n",
        "      distances[query_img].append((distances, gallery_img))\n",
        "\n",
        "  for key in distances: \n",
        "    distances[key].sort()\n",
        "    distances[key] = distances[key][:5]\n",
        "  return distances\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb3dJxztHV_o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo_ni4zt5EVH"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "class FeatureExtractor:\n",
        "    def __init__(self):\n",
        "        # Use VGG-16 as the architecture and ImageNet for the weight\n",
        "        base_model = VGG16(weights='imagenet')\n",
        "        # Customize the model to return features from fully-connected layer\n",
        "        self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
        "    \n",
        "    def extract(self, img):\n",
        "        # Resize the image\n",
        "        img = img.resize((224, 224))\n",
        "        # Convert the image color space\n",
        "        img = img.convert('RGB')\n",
        "        # Reformat the image\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = preprocess_input(x)\n",
        "        # Extract Features\n",
        "        feature = self.model.predict(x)[0]\n",
        "        return feature / np.linalg.norm(feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG-3lRal5eRS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj5PtMUNaJKO"
      },
      "source": [
        "DA RICORDARSI !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDGthQuraHwh"
      },
      "source": [
        "checkpoint_path = \"drive/MyDrive/challenge_AML/checkpoints/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "# Train the model with the new callback\n",
        "'''model.fit(train_images, \n",
        "          train_labels,  \n",
        "          epochs=10,\n",
        "          validation_data=(test_images, test_labels),\n",
        "          callbacks=[cp_callback])  # Pass callback to training'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDTFDr944BIu",
        "outputId": "771e764a-23e1-4ef2-f4d7-8765b4a17f5a"
      },
      "source": [
        "# OUR TRAINING DATASET\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "train_images = preprocess_img(training_paths) \n",
        "autoencoder_train = autoencoder.fit(train_images,train_images, batch_size=32,epochs=50,verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "22/22 [==============================] - 107s 2s/step - loss: 1038545.9742\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5494.7614\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5503.0977\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5511.5277\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5469.8775\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5597.3423\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5526.7040\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5576.5466\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5564.7479\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5431.3470\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5408.3149\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5538.7516\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5575.1920\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5692.0399\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5715.1709\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5529.1355\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5516.6872\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5434.4901\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5534.1453\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5565.7573\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5462.4797\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5524.8009\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5523.1590\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5500.0238\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5626.4143\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5550.5896\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5464.8714\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5544.5657\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5564.3419\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5388.4102\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5481.8178\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5531.3245\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5417.4050\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5577.7963\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5536.9489\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5666.0978\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5488.7283\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5443.7647\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5557.6114\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5425.1872\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5562.0133\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5683.6769\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5437.9344\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5518.6373\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5596.8655\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5624.1422\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5541.6609\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5526.4649\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5454.1826\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 31s 1s/step - loss: 5536.5555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJWY2ztxdRXA"
      },
      "source": [
        "#30 epochs good"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl3apb7d-kXN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "outputId": "2e27d39a-280b-4ddb-d125-6fd18cf61cf8"
      },
      "source": [
        "query_images = extract_features(query_paths, autoencoder)\n",
        "\n",
        "gallery_images = extract_features(gallery_paths,  autoencoder)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-91e4991d7d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgallery_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgallery_paths\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mautoencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-05478ed60a0f>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(paths, model)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mfeatures_ppr_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mflattened_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_ppr_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mnormalized_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflattened_features\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer model_3: expected shape=(None, 224, 224, 3), found shape=(32, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKQxDs469Baw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atoJHg2kDyrq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8lgrPIy4DUE"
      },
      "source": [
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "checkpoint_path = \"drive/MyDrive/challenge_AML/checkpoints/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "# Train the model with the new callback\n",
        "'''model.fit(train_images, \n",
        "          train_labels,  \n",
        "          epochs=10,\n",
        "          validation_data=(test_images, test_labels),\n",
        "          callbacks=[cp_callback])  # Pass callback to training'''\n",
        "\n",
        "# This may generate warnings related to saving the state of the optimizer.\n",
        "# These warnings (and similar warnings throughout this notebook)\n",
        "# are in place to discourage outdated usage, and can be ignored."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL5Lwgch0Of4"
      },
      "source": [
        "def preprocess_img(training_paths):\n",
        "  input_shape = (224, 224, 3)\n",
        "  prep_img=[]\n",
        "  for n in range(len(training_paths)):\n",
        "      img = image.load_img(training_paths[n],\n",
        "                          target_size=(input_shape[0], input_shape[1]))\n",
        "      img_array = image.img_to_array(img) #convert images in 3D arrays authomatically -> must use flatten() to push it into one dimension\n",
        "      expanded_img_array = np.expand_dims(img_array, axis=0) #img_array has shape (None, 3) now; the first dimension need to be added through this command (tf)\n",
        "      preprocessed_img = preprocess_input(expanded_img_array) #images are converted from RGB to BGR (tf)\n",
        "      prep_img.append(preprocessed_img)\n",
        "\n",
        "  prep_img = np.array(prep_img) \n",
        "  return prep_img\n",
        "\n",
        "def extract_features(paths, model) :\n",
        "  nf=[]\n",
        "  np_array = preprocess_img(paths)\n",
        "\n",
        "  for img in np_array:\n",
        "    features_ppr_image = model.predict(img) \n",
        "    flattened_features = features_ppr_image.flatten() \n",
        "    normalized_ft = flattened_features / norm(flattened_features) #normalize\n",
        "    nf.append(normalized_ft)\n",
        "\n",
        "  return nf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1XKed630eK1"
      },
      "source": [
        "def augmented_img(training_paths):\n",
        "\n",
        "      input_shape = (224, 224, 3)\n",
        "      prep_img=[]\n",
        "      img_in_folder=os.listdir(training_paths) #list of images in the folder considered\n",
        "      for el in img_in_folder: #for each image in the considered folder\n",
        "        path=os.path.join(training_paths, el)\n",
        "        print(path)\n",
        "        if path.endswith('jpg'):\n",
        "          img = image.load_img(path, target_size=(input_shape[0], input_shape[1])) #read single image\n",
        "\n",
        "          img_array = image.img_to_array(img) #convert images in 3D arrays authomatically -> must use flatten() to push it into one dimension\n",
        "          expanded_img_array = np.expand_dims(img_array, axis=0) #img_array has shape (None, 3) now; the first dimension need to be added through this command (tf)\n",
        "          preprocessed_img = preprocess_input(expanded_img_array) #images are converted from RGB to BGR (tf)\n",
        "          prep_img.append(preprocessed_img)\n",
        "\n",
        "      for img in prep_img:\n",
        "\n",
        "        i = 0\n",
        "        for batch in datagen.flow(prep_img, \n",
        "                                    batch_size=64, #16\n",
        "                                    save_to_dir=training_paths, \n",
        "                                    save_prefix='aug',\n",
        "                                    save_format='jpg'):    \n",
        "          i += 1    \n",
        "          if i > 5:     \n",
        "            break\n",
        "\n",
        "list_classes = set(training_classes)\n",
        "list_classes.remove(-1)\n",
        "list_classes.add('distractor')\n",
        "list_classes = list(list_classes)\n",
        "for el in list_classes:\n",
        "    folder = os.path.join(training_path, str(el))\n",
        "    #print(folder)\n",
        "    #img_in_folder=os.listdir(folder)\n",
        "    augmented_img(folder)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}